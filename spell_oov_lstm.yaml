#Corpus
data:
    corpus_1:
        path_src: oov_data/train.en
        path_tgt: oov_data/train.vi
    valid:
        path_src: oov_data/val.en
        path_tgt: oov_data/val.vi

# Where the samples will be written
save_data: oov_data/vocab
# Where the vocab(s) will be written
src_vocab: oov_data/vocab/vocab.en
tgt_vocab: oov_data/vocab/vocab.vi

src_vocab_size: 64
tgt_vocab_size: 64
# Prevent overwriting existing files in the folder
overwrite: False

save_model: model/lstm_oov
save_checkpoint_steps: 2000
keep_checkpoint: 10
#train_from: iwslt_2015/model_step_20000.pt
seed: 3435
train_steps: 100000
valid_steps: 2000
#valid_batch_size: 1
report_every: 100
early_stopping: 4
early_stopping_criteria: accuracy

decoder_type: rnn
encoder_type: brnn
word_vec_size: 64
rnn_size: 64
enc_layers: 1
dec_layers: 1
#transformer_ff: 2048
#heads: 8

accum_count: 8
optim: adam
adam_beta1: 0.9
adam_beta2: 0.998
decay_method: noam
learning_rate: 2.0
max_grad_norm: 0.0

batch_size: 1024
batch_type: tokens
normalization: tokens
dropout: 0.1
label_smoothing: 0.1

max_generator_batches: 2

param_init: 0.0
param_init_glorot: 'true'
position_encoding: 'true'

tensorboard: True

world_size: 1
gpu_ranks: 0
